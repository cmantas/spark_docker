version: '2'
services:
  namenode:
    build:
      context: ./images/hadoop
    container_name: namenode
    command: /bin/bash -c '/run_namenode.sh'
    volumes:
      - ./data/namenode:/hadoop/dfs/name
      - ./logs/:/hadoop/logs
    environment:
      - CLUSTER_NAME=test
      - HDFS_REPLICATION=1
      - HDFS_BLOCKSIZE=128m
    env_file:
      - ./resources/hadoop.env
    network_mode: host
  spark-master:
    build:
      context: ./images/spark
    container_name: spark-master
    environment:
      - ENABLE_INIT_DAEMON=false
      - SPARK_MASTER_HOST=$MASTER
    network_mode: host
    command: /bin/bash -c '/spark/sbin/start-master.sh && tail -f /dev/null'
  jupyter-pyspark:
    build:
      context: ./images/jupyter
    container_name: jupyter-pyspark
    network_mode: host
    command: /bin/bash -c 'start-notebook.sh --NotebookApp.token="" --port=8889'
    volumes:
      - ./notebooks:/home/jovyan
  hdfs-browser:
    image: gethue/hue:latest
    network_mode: host
    volumes:
      - ./logs/:/logs
